{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dir to parent\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "db_name = \"budget_vector_db\"\n",
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "pdf_input = r'knowledge_base\\2025\\fy2025_budget_statement.pdf'\n",
    "source_name = \"fy2025_budget_statement.pdf\"\n",
    "doc_type = \"budget_statement\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sections extraction from table of contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract table of contents\n",
    "def extract_sections_from_toc(pdf_path, toc_pages=(0, 1)):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    sections = []\n",
    "    for i in range(toc_pages[0], toc_pages[1]+1):\n",
    "        page = reader.pages[i]\n",
    "        text = page.extract_text()\n",
    "        for line in text.split('\\n'):\n",
    "            match = re.match(r'^([A-Z]\\.\\s.+?)\\.{3,}\\s+(\\d+)$', line.strip())\n",
    "            if match:\n",
    "                title = match.group(1).strip()\n",
    "                page_num = int(match.group(2))\n",
    "                sections.append((title, page_num))\n",
    "    return sections\n",
    "\n",
    "# cleaning\n",
    "def clean_section_titles(raw_sections):\n",
    "    cleaned = []\n",
    "    for raw_title, page_num in raw_sections:\n",
    "        # Remove leading \"A. \", \"B. \", etc.\n",
    "        title = re.sub(r'^[A-Z]\\.\\s+', '', raw_title)\n",
    "\n",
    "        # Remove trailing dot runs or dot-space-dot junk\n",
    "        title = re.sub(r'\\.{2,}', '', title)\n",
    "\n",
    "        # Collapse internal double spaces (in case)\n",
    "        title = re.sub(r'\\s{2,}', ' ', title)\n",
    "\n",
    "        # Final trim\n",
    "        title = title.strip()\n",
    "\n",
    "        cleaned.append((title, page_num))\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sections = extract_sections_from_toc(pdf_input)\n",
    "sections = clean_section_titles(raw_sections)\n",
    "print(sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text extraction and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page_texts(pdf_path, start_page=0, page_offset = 0):\n",
    "    \"\"\"\n",
    "    Extracts raw text from each page starting from `start_page`.\n",
    "    Returns a list of dicts: [{page_num, text}]\n",
    "    \"\"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    pages = []\n",
    "\n",
    "    for page_num in range(start_page, len(reader.pages)):\n",
    "        raw_text = reader.pages[page_num].extract_text()\n",
    "        if not raw_text:\n",
    "            continue\n",
    "\n",
    "        pages.append({\n",
    "            \"page_num\": page_num + page_offset,\n",
    "            \"text\": raw_text\n",
    "        })\n",
    "\n",
    "    return pages\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans page text by removing footers like 'Page 3 of 86'.\n",
    "    \"\"\"\n",
    "    cleaned_lines = []\n",
    "    for line in text.split('\\n'):\n",
    "        # Remove footer if line contains \"Page x of y\"\n",
    "        if re.search(r'\\bPage\\s*\\d+\\s+of\\s+\\d+\\b', line, re.IGNORECASE):\n",
    "            continue\n",
    "        cleaned_lines.append(line)\n",
    "    \n",
    "    return '\\n'.join(cleaned_lines).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pages = extract_page_texts(pdf_input, start_page=2, page_offset=1)  # Skip ToC\n",
    "\n",
    "# Apply cleaning\n",
    "cleaned_pages = []\n",
    "for page in raw_pages:\n",
    "    cleaned_pages.append({\n",
    "        \"page_num\": page[\"page_num\"],\n",
    "        \"text\": clean_text(page[\"text\"])\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_pages[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_metadata_tuples(sections, cleaned_pages, offset=0, source=None, doc_type=None):\n",
    "    \"\"\"\n",
    "    Assumes sections is a list of tuples (section_name, start_page) using the original numbering.\n",
    "    If cleaned_pages have an offset (e.g. missing TOC), subtract the offset from the section start pages.\n",
    "    \n",
    "    Parameters:\n",
    "      sections (list of tuple): e.g. [('Introduction', 3), ...]\n",
    "      cleaned_pages (list of dict): Each with keys 'page_num' and 'text'.\n",
    "      offset (int): The number to subtract from each section's start page.\n",
    "      source (str, optional): The base file name or identifier for the document.\n",
    "      doc_type (str, optional): A string indicating the document type (e.g., \"budget_statement\").\n",
    "                    \n",
    "    Returns:\n",
    "      List of dict: Each page dict includes its original keys plus added metadata:\n",
    "                    'section', 'source' (if provided), and 'doc_type' (if provided).\n",
    "    \"\"\"\n",
    "    # Adjust the section start pages using the offset.\n",
    "    adjusted_sections = [(name, start_page - offset) for name, start_page in sections]\n",
    "    \n",
    "    # Sort the sections by the adjusted start page.\n",
    "    sections_sorted = sorted(adjusted_sections, key=lambda x: x[1])\n",
    "    \n",
    "    # Determine the maximum page number among cleaned pages.\n",
    "    max_page = max(page['page_num'] for page in cleaned_pages)\n",
    "    \n",
    "    # Build section ranges: (section_name, start_page, end_page)\n",
    "    section_ranges = []\n",
    "    for idx, (section_name, start_page) in enumerate(sections_sorted):\n",
    "        if idx < len(sections_sorted) - 1:\n",
    "            next_start = sections_sorted[idx + 1][1]\n",
    "            end_page = next_start - 1\n",
    "        else:\n",
    "            end_page = max_page\n",
    "        section_ranges.append((section_name, start_page, end_page))\n",
    "    \n",
    "    # Annotate each cleaned page with its section and additional metadata.\n",
    "    metadata_pages = []\n",
    "    for page in cleaned_pages:\n",
    "        page_num = page['page_num']\n",
    "        assigned_section = \"Not Assigned\"\n",
    "        for section_name, start_page, end_page in section_ranges:\n",
    "            if start_page <= page_num <= end_page:\n",
    "                assigned_section = section_name\n",
    "                break\n",
    "        page_with_metadata = page.copy()\n",
    "        page_with_metadata['section'] = assigned_section\n",
    "        if source is not None:\n",
    "            page_with_metadata['source'] = source\n",
    "        if doc_type is not None:\n",
    "            page_with_metadata['doc_type'] = doc_type\n",
    "        metadata_pages.append(page_with_metadata)\n",
    "    \n",
    "    return metadata_pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_pages = build_metadata_tuples(sections, cleaned_pages, offset=0, source=source_name, doc_type=doc_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_pages[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langchain_chunk_texts(metadata_pages, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Uses LangChain's RecursiveCharacterTextSplitter to split each page's text into chunks\n",
    "    with a specified size and overlap. Each chunk is enriched with metadata from the original page.\n",
    "\n",
    "    Parameters:\n",
    "      metadata_pages (list): List of dicts with keys 'page_num', 'text', and 'section'.\n",
    "      chunk_size (int): Maximum number of characters per chunk.\n",
    "      chunk_overlap (int): Overlap in characters between consecutive chunks.\n",
    "      \n",
    "    Returns:\n",
    "      List of dict: Each dict represents a chunk with keys 'chunk_text', 'section', and 'page_nums'.\n",
    "    \"\"\"\n",
    "    # Initialize the splitter with the desired parameters.\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \"]  # Order of preference for splitting.\n",
    "    )\n",
    "    \n",
    "    chunks = []\n",
    "    for page in metadata_pages:\n",
    "        # Use the splitter to divide the text into chunks.\n",
    "        splits = splitter.split_text(page['text'])\n",
    "        for chunk in splits:\n",
    "            chunks.append({\n",
    "                \"content\": chunk,\n",
    "                \"section\": page['section'],\n",
    "                \"page_nums\": page['page_num'],\n",
    "                \"source\":page[\"source\"],\n",
    "                \"doc_type\": page[\"doc_type\"]\n",
    "            })\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_temp = langchain_chunk_texts(metadata_pages, chunk_size=1000, chunk_overlap=200)\n",
    "chunks_temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_chunks_to_documents(chunks):\n",
    "    \"\"\"\n",
    "    Converts chunk dictionaries to a new structure with separate context and metadata.\n",
    "\n",
    "    Parameters:\n",
    "      chunks (list of dict): Each dict contains keys \"content\", \"section\", \"page_nums\", etc.\n",
    "      source (str, optional): The source file name.\n",
    "      doc_type (str, optional): The document type (e.g., \"budget_statement\").\n",
    "\n",
    "    Returns:\n",
    "      List of dict: Each dict has 'context' for the text and 'metadata' for the associated metadata.\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    for chunk in chunks:\n",
    "        doc = {\n",
    "            \"context\": chunk[\"content\"],\n",
    "            \"metadata\": {\n",
    "                \"section\": chunk[\"section\"],\n",
    "                \"page_num\": chunk[\"page_nums\"],\n",
    "                \"source\": chunk[\"source\"],\n",
    "                \"doc_type\": chunk[\"doc_type\"]\n",
    "            }\n",
    "        }\n",
    "        docs.append(doc)\n",
    "    return docs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = convert_chunks_to_documents(chunks_temp)\n",
    "chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to LangChain Document objects\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=chunk[\"context\"],\n",
    "        metadata=chunk[\"metadata\"]\n",
    "    )\n",
    "    for chunk in chunks\n",
    "]\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings()  # or HuggingFaceEmbeddings(...) if you prefer free\n",
    "\n",
    "# Delete previous DB if exists\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "# Create and persist vectorstore\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=db_name\n",
    ")\n",
    "\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one vector and find how many dimensions it has\n",
    "\n",
    "collection = vectorstore._collection\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"The vectors have {dimensions:,} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prework (with thanks to Jon R for identifying and fixing a bug in this!)\n",
    "\n",
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "vectors = np.array(result['embeddings'])\n",
    "documents = result['documents']\n",
    "metadatas = result['metadatas']\n",
    "doc_types = [metadata['doc_type'] for metadata in metadatas]\n",
    "colors = [['blue'][['budget_statement'].index(t)] for t in doc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We humans find it easier to visalize things in 2D!\n",
    "# Reduce the dimensionality of the vectors to 2D using t-SNE\n",
    "# (t-distributed stochastic neighbor embedding)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 2D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x',yaxis_title='y'),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new Chat with OpenAI\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "\n",
    "# set up the conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', output_key='answer', return_messages=True)\n",
    "\n",
    "# the retriever is an abstraction over the VectorStore that will be used during RAG; k is how many chunks to use\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 25})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg = (\n",
    "    \"You are a knowledgeable assistant that provides clear, concise insights on Singapore’s budgets. \"\n",
    "    \"You may compare and reference details from any provided documents. If the user asks about details \"\n",
    "    \"beyond these documents, explain that the information is not available. Always base your answers on the \"\n",
    "    \"documents you have, and do not speculate or fabricate information. When making comparisons or referencing \"\n",
    "    \"specific details, cite the relevant sections or years to support your explanation.\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(system_msg),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"Here are some documents to help you:\\n\\n{context}\\n\\nNow answer the question: {question}\"\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    memory=memory, \n",
    "    return_source_documents=True,\n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt}  # inject custom system prompt\n",
    "\n",
    ")\n",
    "\n",
    "# debug\n",
    "result = conversation_chain.invoke({\"question\": \"describe the tax changes\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(question, history):\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    answer = result.get(\"answer\", \"\")\n",
    "\n",
    "    source_docs = result.get(\"source_documents\", [])\n",
    "    if source_docs:\n",
    "        metadata_lines = []\n",
    "        for i, doc in enumerate(source_docs, start=1):\n",
    "            md = doc.metadata\n",
    "            src = md.get(\"source\", \"Unknown source\")\n",
    "            sec = md.get(\"section\", \"Unknown section\")\n",
    "            pg = md.get(\"page_num\", \"Unknown page\")\n",
    "            metadata_lines.append(f\"**Document {i}:** Source: {src} | Section: {sec} | Page: {pg}\")\n",
    "\n",
    "        answer += \"\\n\\n**Sources:**\\n\" + \"\\n\".join(metadata_lines)\n",
    "    else:\n",
    "        answer += \"\\n\\n**NO SOURCE:**\\n\"\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And in Gradio:\n",
    "\n",
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and constants\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "db_name = \"budget_vector_db\"\n",
    "MODEL = 'gpt-4o-mini'\n",
    "\n",
    "# Find all PDF files in the knowledge_base directory and its subdirectories.\n",
    "pdf_files = glob.glob(r'knowledge_base/**/*.pdf', recursive=True)\n",
    "\n",
    "all_chunks = []\n",
    "\n",
    "for pdf_path in pdf_files:\n",
    "    # Extract source name from the file path.\n",
    "    source_name = os.path.basename(pdf_path)\n",
    "    \n",
    "    # Extract year from the file path and set doc_type\n",
    "    year_match = re.search(r'fy(\\d{4})_budget_statement\\.pdf', source_name)\n",
    "    if year_match:\n",
    "        year = year_match.group(1)\n",
    "        doc_type = f\"budget_statement_{year}\"  # or just year, if you prefer\n",
    "    else:\n",
    "        doc_type = \"budget_statement\"  # Default doc_type if year extraction fails\n",
    "\n",
    "    # Extract sections and clean them.\n",
    "    raw_sections = extract_sections_from_toc(pdf_path)\n",
    "    sections = clean_section_titles(raw_sections)\n",
    "\n",
    "    # Extract page texts and clean them.\n",
    "    raw_pages = extract_page_texts(pdf_path, start_page=2, page_offset=1)\n",
    "    cleaned_pages = [{\n",
    "        \"page_num\": page[\"page_num\"],\n",
    "        \"text\": clean_text(page[\"text\"])\n",
    "    } for page in raw_pages]\n",
    "\n",
    "    # Build metadata.\n",
    "    metadata_pages = build_metadata_tuples(sections, cleaned_pages, offset=0, source=source_name, doc_type=doc_type)\n",
    "\n",
    "    # Chunk the text.\n",
    "    chunks_temp = langchain_chunk_texts(metadata_pages, chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "    # Convert chunks to documents.\n",
    "    chunks = convert_chunks_to_documents(chunks_temp)\n",
    "\n",
    "    # Append chunks to all_chunks\n",
    "    all_chunks.extend(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_44028\\1952476791.py:17: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 242 documents\n"
     ]
    }
   ],
   "source": [
    "# Convert to LangChain Document objects\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=chunk[\"context\"],\n",
    "        metadata=chunk[\"metadata\"]\n",
    "    )\n",
    "    for chunk in all_chunks\n",
    "]\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings()  # or HuggingFaceEmbeddings(...) if you prefer free\n",
    "\n",
    "# Delete previous DB if exists\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "# Create and persist vectorstore\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=db_name\n",
    ")\n",
    "\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 242 documents\n"
     ]
    }
   ],
   "source": [
    "# Convert to LangChain Document objects\n",
    "docs = [Document(page_content=chunk[\"context\"], metadata=chunk[\"metadata\"]) for chunk in all_chunks]\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Delete previous DB if exists\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "# Create and persist vectorstore\n",
    "vectorstore = Chroma.from_documents(documents=docs, embedding=embeddings, persist_directory=db_name)\n",
    "\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_44028\\3282748017.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_44028\\3282748017.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_history', output_key='answer', return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "# create a new Chat with OpenAI\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "\n",
    "# set up the conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', output_key='answer', return_messages=True)\n",
    "\n",
    "# the retriever is an abstraction over the VectorStore that will be used during RAG; k is how many chunks to use\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 25})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import re\n",
    "\n",
    "# ✅ Strict but flexible system message\n",
    "system_msg = (\n",
    "    \"You are a highly reliable assistant answering questions based on Singapore’s FY2024 and FY2025 budget documents. \"\n",
    "    \"You MUST use only the content from these documents. You MAY summarize and synthesize across them, including comparing statistics across FY2024 and FY2025 when both are available in the retrieved content. Do not guess or fabricate any data. \"\n",
    "    \"If the answer is not even indirectly supported by the documents, respond: 'I do not have sufficient information based on the provided documents.' \"\n",
    "    \"Only mention fiscal years FY2024 and FY2025 unless another year is explicitly stated in the documents.\"\n",
    ")\n",
    "\n",
    "# ✅ Flexible user instruction (no hardcoded fallback terms like GDP)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(system_msg),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"Here are some documents to help you:\\n\\n{context}\\n\\n\"\n",
    "        \"Now answer the question: {question}\\n\\n\"\n",
    "        \"If the documents do not directly answer the question, but contain related figures or closely associated statistics, you MAY include them with a clear disclaimer explaining how they are related.\"\n",
    "    )\n",
    "])\n",
    "\n",
    "# ✅ Conversation memory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history',\n",
    "    output_key='answer',\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# ✅ Main function\n",
    "def chat(question: str, history) -> str:\n",
    "    # Try to detect specific year\n",
    "    match = re.search(r'fy\\s*(20\\d{2})|(?:[^0-9]|^)(20\\d{2})(?:[^0-9]|$)', question.lower())\n",
    "    year = match.group(1) or match.group(2) if match else None\n",
    "\n",
    "    # ✅ Comparison detection — don't filter if comparing both years\n",
    "    if \"compare\" in question.lower() and \"2024\" in question and \"2025\" in question:\n",
    "        filter_kwargs = {}\n",
    "    elif year in {\"2024\", \"2025\"}:\n",
    "        target_source = f\"fy{year}_budget_statement.pdf\"\n",
    "        filter_kwargs = {\"where\": {\"source\": {\"$eq\": target_source}}}\n",
    "    else:\n",
    "        filter_kwargs = {}\n",
    "\n",
    "    print(f\"[DEBUG] Running retrieval with filter: {filter_kwargs.get('where', 'None')}\")\n",
    "\n",
    "    # Initial retriever\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\n",
    "        \"k\": 25,\n",
    "        **({\"filter\": filter_kwargs[\"where\"]} if \"where\" in filter_kwargs else {})\n",
    "    })\n",
    "    docs = retriever.invoke(question)\n",
    "\n",
    "    # ✅ Retry without filter if nothing found\n",
    "    if not docs and filter_kwargs:\n",
    "        print(\"[DEBUG] No results with filter. Retrying without filter...\")\n",
    "        retriever = vectorstore.as_retriever(search_kwargs={\"k\": 25})\n",
    "        docs = retriever.invoke(question)\n",
    "\n",
    "    print(f\"[DEBUG] Retrieved {len(docs)} documents\")\n",
    "    print(f\"[DEBUG] Sources in retrieval: {[doc.metadata.get('source') for doc in docs]}\")\n",
    "\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        print(f\"[Doc {i}] {doc.metadata.get('source', 'Unknown')} | \"\n",
    "              f\"Section: {doc.metadata.get('section', 'Unknown')} | \"\n",
    "              f\"Page: {doc.metadata.get('page_num', 'Unknown')}\")\n",
    "\n",
    "    # ✅ Setup chain\n",
    "    chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        memory=memory,\n",
    "        return_source_documents=True,\n",
    "        combine_docs_chain_kwargs={\"prompt\": prompt},\n",
    "        output_key=\"answer\"\n",
    "    )\n",
    "\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    answer = result.get(\"answer\", \"\")\n",
    "    source_docs = result.get(\"source_documents\", [])\n",
    "\n",
    "    # ✅ Format citations\n",
    "    metadata_lines = []\n",
    "    for i, doc in enumerate(source_docs, 1):\n",
    "        md = doc.metadata\n",
    "        src = md.get(\"source\", \"Unknown source\")\n",
    "        sec = md.get(\"section\", \"Unknown section\")\n",
    "        pg = md.get(\"page_num\", \"Unknown page\")\n",
    "        metadata_lines.append(f\"**Doc {i}:** {src} | {sec} | Page {pg}\")\n",
    "\n",
    "    if metadata_lines:\n",
    "        answer += \"\\n\\n**Sources:**\\n\" + \"\\n\".join(metadata_lines)\n",
    "    else:\n",
    "        answer += \"\\n\\n**No Sources Found**\"\n",
    "\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7876\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7876/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Running retrieval with filter: None\n",
      "[DEBUG] Retrieved 25 documents\n",
      "[DEBUG] Sources in retrieval: ['fy2024_budget_statement.pdf', 'fy2025_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2025_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2025_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2025_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2025_budget_statement.pdf', 'fy2025_budget_statement.pdf', 'fy2025_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2025_budget_statement.pdf', 'fy2025_budget_statement.pdf', 'fy2025_budget_statement.pdf', 'fy2025_budget_statement.pdf', 'fy2025_budget_statement.pdf', 'fy2024_budget_statement.pdf']\n",
      "[Doc 1] fy2024_budget_statement.pdf | Section: Securing Our Fiscal Position | Page: 80\n",
      "[Doc 2] fy2025_budget_statement.pdf | Section: Fiscal Position | Page: 90\n",
      "[Doc 3] fy2024_budget_statement.pdf | Section: Securing Our Fiscal Position | Page: 80\n",
      "[Doc 4] fy2025_budget_statement.pdf | Section: Fiscal Position | Page: 91\n",
      "[Doc 5] fy2024_budget_statement.pdf | Section: Securing Our Fiscal Position | Page: 79\n",
      "[Doc 6] fy2024_budget_statement.pdf | Section: Securing Our Fiscal Position | Page: 79\n",
      "[Doc 7] fy2024_budget_statement.pdf | Section: Introduction | Page: 8\n",
      "[Doc 8] fy2024_budget_statement.pdf | Section: Securing Our Fiscal Position | Page: 78\n",
      "[Doc 9] fy2024_budget_statement.pdf | Section: Introduction | Page: 4\n",
      "[Doc 10] fy2024_budget_statement.pdf | Section: Introduction | Page: 3\n",
      "[Doc 11] fy2025_budget_statement.pdf | Section: Introduction | Page: 3\n",
      "[Doc 12] fy2024_budget_statement.pdf | Section: Conclusion | Page: 83\n",
      "[Doc 13] fy2025_budget_statement.pdf | Section: Fiscal Position | Page: 92\n",
      "[Doc 14] fy2024_budget_statement.pdf | Section: Securing Our Fiscal Position | Page: 70\n",
      "[Doc 15] fy2025_budget_statement.pdf | Section: Fiscal Position | Page: 94\n",
      "[Doc 16] fy2025_budget_statement.pdf | Section: Building a Sustainable City | Page: 72\n",
      "[Doc 17] fy2025_budget_statement.pdf | Section: Introduction | Page: 7\n",
      "[Doc 18] fy2024_budget_statement.pdf | Section: Tackling Immediate Challenges | Page: 9\n",
      "[Doc 19] fy2024_budget_statement.pdf | Section: Pursuing Better Growth and Jobs | Page: 19\n",
      "[Doc 20] fy2025_budget_statement.pdf | Section: Introduction | Page: 8\n",
      "[Doc 21] fy2025_budget_statement.pdf | Section: Tackling Cost Pressures | Page: 15\n",
      "[Doc 22] fy2025_budget_statement.pdf | Section: Introduction | Page: 6\n",
      "[Doc 23] fy2025_budget_statement.pdf | Section: Tackling Cost Pressures | Page: 16\n",
      "[Doc 24] fy2025_budget_statement.pdf | Section: Fiscal Position | Page: 93\n",
      "[Doc 25] fy2024_budget_statement.pdf | Section: Tackling Immediate Challenges | Page: 12\n",
      "[DEBUG] Running retrieval with filter: {'source': {'$eq': 'fy2024_budget_statement.pdf'}}\n",
      "[DEBUG] Retrieved 25 documents\n",
      "[DEBUG] Sources in retrieval: ['fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf', 'fy2024_budget_statement.pdf']\n",
      "[Doc 1] fy2024_budget_statement.pdf | Section: Introduction | Page: 8\n",
      "[Doc 2] fy2024_budget_statement.pdf | Section: Securing Our Fiscal Position | Page: 78\n",
      "[Doc 3] fy2024_budget_statement.pdf | Section: Securing Our Fiscal Position | Page: 79\n",
      "[Doc 4] fy2024_budget_statement.pdf | Section: Securing Our Fiscal Position | Page: 79\n",
      "[Doc 5] fy2024_budget_statement.pdf | Section: Securing Our Fiscal Position | Page: 70\n",
      "[Doc 6] fy2024_budget_statement.pdf | Section: Conclusion | Page: 83\n",
      "[Doc 7] fy2024_budget_statement.pdf | Section: Pursuing Better Growth and Jobs | Page: 19\n",
      "[Doc 8] fy2024_budget_statement.pdf | Section: Securing Our Fiscal Position | Page: 80\n",
      "[Doc 9] fy2024_budget_statement.pdf | Section: Tackling Immediate Challenges | Page: 9\n",
      "[Doc 10] fy2024_budget_statement.pdf | Section: Securing Our Fiscal Position | Page: 80\n",
      "[Doc 11] fy2024_budget_statement.pdf | Section: Introduction | Page: 4\n",
      "[Doc 12] fy2024_budget_statement.pdf | Section: Introduction | Page: 3\n",
      "[Doc 13] fy2024_budget_statement.pdf | Section: Tackling Immediate Challenges | Page: 12\n",
      "[Doc 14] fy2024_budget_statement.pdf | Section: Pursuing Better Growth and Jobs | Page: 18\n",
      "[Doc 15] fy2024_budget_statement.pdf | Section: Pursuing Better Growth and Jobs | Page: 20\n",
      "[Doc 16] fy2024_budget_statement.pdf | Section: Introduction | Page: 5\n",
      "[Doc 17] fy2024_budget_statement.pdf | Section: Pursuing Better Growth and Jobs | Page: 16\n",
      "[Doc 18] fy2024_budget_statement.pdf | Section: Introduction | Page: 7\n",
      "[Doc 19] fy2024_budget_statement.pdf | Section: Pursuing Better Growth and Jobs | Page: 15\n",
      "[Doc 20] fy2024_budget_statement.pdf | Section: Pursuing Better Growth and Jobs | Page: 17\n",
      "[Doc 21] fy2024_budget_statement.pdf | Section: Forging a Stronger and More United Nation | Page: 58\n",
      "[Doc 22] fy2024_budget_statement.pdf | Section: Providing More Assurance for Families and Seniors | Page: 47\n",
      "[Doc 23] fy2024_budget_statement.pdf | Section: Pursuing Better Growth and Jobs | Page: 21\n",
      "[Doc 24] fy2024_budget_statement.pdf | Section: Pursuing Better Growth and Jobs | Page: 26\n",
      "[Doc 25] fy2024_budget_statement.pdf | Section: Providing More Assurance for Families and Seniors | Page: 53\n"
     ]
    }
   ],
   "source": [
    "# And in Gradio:\n",
    "\n",
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what is the budget deficit for 2024\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc_type': 'budget_statement_2024', 'page_num': 80, 'section': 'Securing Our Fiscal Position', 'source': 'fy2024_budget_statement.pdf'}\n",
      "we expect to end FY2023 with a deficit of $3.6 billion , or 0.5%  of GDP .  \n",
      " \n",
      "172. For FY2024, we are budgeting a small surplus of $0.8 billion, or \n",
      "0.1% of GDP , which is essentially a balanced fiscal position. The \n",
      "overall stance is appropriate , as we are  provid ing targeted support\n",
      "{'doc_type': 'budget_statement_2024', 'page_num': 80, 'section': 'Securing Our Fiscal Position', 'source': 'fy2024_budget_statement.pdf'}\n",
      "economies where public finances are on an unsustainable path, and \n",
      "fiscal systems are at risk of breaking. We must never allow this to \n",
      "happen in Singapore. Instead , let us uphold the ethos of fiscal \n",
      "discipline and responsibility that has served us well, and ensure  that \n",
      "our fiscal position  always  remains balanced , sound, and sustainable.   \n",
      " \n",
      "FY2023 and FY2024 Fiscal Position  \n",
      " \n",
      "168. Sir, \n",
      "{'doc_type': 'budget_statement_2025', 'page_num': 91, 'section': 'Fiscal Position', 'source': 'fy2025_budget_statement.pdf'}\n",
      "Changi Terminal 5, and for the energy transition .   \n",
      " \n",
      "173. Overall , I expect to end FY2024 with a surplus of $6.4 billion , or \n",
      "0.9%  of GDP .   \n",
      " \n",
      "174. For FY2025, I expect a similar fiscal position , with a surplus of \n",
      "$6.8 billion, or 0.9% of GDP .\n",
      "{'doc_type': 'budget_statement_2024', 'page_num': 79, 'section': 'Securing Our Fiscal Position', 'source': 'fy2024_budget_statement.pdf'}\n",
      "d. We will have to spend more for the major moves to \n",
      "decarbonise our economy , as I explained earlier .  \n",
      " \n",
      "e. As part of Forward Singapore , we are making significant \n",
      "policy shifts to strengthen our social safety nets, and \n",
      "provide more assurance to Singaporeans. I have just \n",
      "introduced some of these measures in this year’s Budget.  \n",
      "We will spend around $5 billion on Forward S ingapore  \n",
      "polic\n",
      "{'doc_type': 'budget_statement_2024', 'page_num': 79, 'section': 'Securing Our Fiscal Position', 'source': 'fy2024_budget_statement.pdf'}\n",
      "balanced budget over the coming years.  \n",
      " \n",
      "166. But the medium -term fiscal position is tight. Because  there are \n",
      "so many pressures for us to spend more, be it on healthcare, social \n",
      "needs , or the energy transition , and these are all big -ticket items . We \n",
      "will have to manage th ese expenditures carefully, or we will end up \n",
      "with a significant funding gap .\n",
      "{'doc_type': 'budget_statement_2024', 'page_num': 8, 'section': 'Introduction', 'source': 'fy2024_budget_statement.pdf'}\n",
      "d. In this Budget, we will roll out the first instalment of our \n",
      "Forward S ingapore  programmes.   \n",
      " \n",
      "11. Budget 2024 is therefore about taking concrete steps to build \n",
      "our shared future together. We will:  \n",
      " \n",
      "a. Tackle immediate challenge s for households and \n",
      "businesses ;  \n",
      " \n",
      "b. Pursue better jobs, better growth , and equip our workers \n",
      "for life;  \n",
      " \n",
      "c. Create more paths for equality and mobilit\n",
      "{'doc_type': 'budget_statement_2025', 'page_num': 90, 'section': 'Fiscal Position', 'source': 'fy2025_budget_statement.pdf'}\n",
      "FY2024 and FY2025 Fiscal Position  \n",
      " \n",
      "168. Let me turn to  our latest fiscal position .   \n",
      " \n",
      "169. For F inancial Year 2024, our revenue collections were better \n",
      "than expected .   \n",
      " \n",
      "170. A key reason is the upside in our Corporate Income Tax .   \n",
      " \n",
      "a. In the past, our Corporate Income Tax collections were quite \n",
      "stable, at about 3.2% of GDP .   \n",
      " \n",
      "b. But collections  increased significantly in the\n",
      "{'doc_type': 'budget_statement_2025', 'page_num': 72, 'section': 'Building a Sustainable City', 'source': 'fy2025_budget_statement.pdf'}\n",
      "next year .  The enhancements are expected to cost  around  $300  \n",
      "million  in FY 2026, and more in future years, as our population \n",
      "continues to age .\n",
      "{'doc_type': 'budget_statement_2024', 'page_num': 9, 'section': 'Tackling Immediate Challenges', 'source': 'fy2024_budget_statement.pdf'}\n",
      "$10 billion.   \n",
      " \n",
      "17. While we expect the situation to improve this year, there are \n",
      "uncertainties in the outlook  as I mentioned just now . So in this \n",
      "Budget, I will do more to support  households  and further enhance \n",
      "the Assurance Package .\n",
      "{'doc_type': 'budget_statement_2025', 'page_num': 92, 'section': 'Fiscal Position', 'source': 'fy2025_budget_statement.pdf'}\n",
      "Medium -Term Fiscal Outlook  \n",
      " \n",
      "175. We will continue to keep an eye on our medium -term fiscal \n",
      "projections .   \n",
      " \n",
      "176. In 2023, the Ministry of Finance released an Occasional Paper \n",
      "showing that we expect to keep our fiscal position roughly balanced \n",
      "until 2030 .  For now, this remains our assessment .  And l et me \n",
      "explain .   \n",
      " \n",
      "177. There is still considerable uncertainty about how Government\n"
     ]
    }
   ],
   "source": [
    "query = \"what is the budget deficit for 2025\"\n",
    "docs = vectorstore.as_retriever(search_kwargs={\"k\": 10}).get_relevant_documents(query)\n",
    "for d in docs:\n",
    "    print(d.metadata)\n",
    "    print(d.page_content[:400])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What does the FY2025 budget document say about government spending as a % of GDP\"\n",
    "docs = vectorstore.as_retriever(search_kwargs={\"k\": 100}).get_relevant_documents(query)\n",
    "\n",
    "for d in docs:\n",
    "    print(f\"{d.metadata['source']} | Page {d.metadata['page_num']} | {d.metadata['section']}\")\n",
    "    print(d.page_content[:300], \"\\n---\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
